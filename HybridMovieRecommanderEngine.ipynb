{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CagataySencan/Hybrid-Movie-Recommender-System/blob/main/HybridMovieRecommanderEngine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ1wLfS4iuGk"
      },
      "source": [
        "# Genel Hazırlıklar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hv65UC4uKgqX"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy as stats\n",
        "from ast import literal_eval\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "!pip install scikit-surprise\n",
        "from scipy.sparse import csr_matrix\n",
        "from surprise import Reader,Dataset,SVD\n",
        "from surprise.model_selection import cross_validate\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCayD8VrIfhz"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ug743yU_I9Uy"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UG9-pxr-I_1g"
      },
      "outputs": [],
      "source": [
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Tn9ts8oiJGIK"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mE8xqPPJHoN"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download rounakbanik/the-movies-dataset\n",
        "! kaggle datasets download tmdb/tmdb-movie-metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrA6mlG8JVdo"
      },
      "outputs": [],
      "source": [
        "! unzip /content/the-movies-dataset.zip\n",
        "! unzip /content/tmdb-movie-metadata.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5Nmr04izKI0H"
      },
      "outputs": [],
      "source": [
        "credits = pd.DataFrame(pd.read_csv('credits.csv'))\n",
        "keywords = pd.DataFrame(pd.read_csv('keywords.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxF-AvSjilwU"
      },
      "source": [
        "# Content Based Filtering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peLUEfwX5bsh"
      },
      "outputs": [],
      "source": [
        "# Content based filtering için hazırlık\n",
        "movies_metadata_tmdb = pd.DataFrame(pd.read_csv('tmdb_5000_movies.csv'))\n",
        "movies_tmdb_credits = pd.DataFrame(pd.read_csv('tmdb_5000_credits.csv'))\n",
        "content_based_movies = movies_metadata_tmdb[['overview','title','genres', 'keywords']]\n",
        "content_based_credits = movies_tmdb_credits[['cast','crew','movie_id']]\n",
        "content_based = content_based_movies.join(content_based_credits)\n",
        "# Yeterli veri olduğu için eksik veri olan satırları çıkartma kararı aldım\n",
        "content_based = content_based.dropna()\n",
        "\n",
        "# Bu filtreden en yüksek verimi alabilmek için iki alt filtreye bölme kararı aldım\n",
        "# İlk filtre önerileri overview'a, ikincisi ise cast, crew, keyword, genre gibi parametrelere göre öneri yapacak\n",
        "# Bu filtrede memory yetersizliği nedeniyle cosine similarity score hesaplayamadığım için TMDB 5000 Movie Dataset'i kullandım\n",
        "content_based.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5QQ8Zjdi3fi"
      },
      "source": [
        "### Overview Bazlı Filtre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5jKm550idj_"
      },
      "outputs": [],
      "source": [
        "# overview bazlı filtre :\n",
        "\n",
        "overview_based = content_based[['title','overview']]\n",
        "print(overview_based.isnull().sum())\n",
        "print(overview_based.head())\n",
        "\n",
        "# Vektörleştirme işlemi \n",
        "\n",
        "tf_idf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix_overview = tf_idf.fit_transform(overview_based['overview'])\n",
        "\n",
        "\n",
        "# Filmler arasındaki benzerlikleri nümerik bir skorla görmek için 'cosine similarity score' hesabı yapma kararı aldım\n",
        "tfidf_matrix_overview.shape\n",
        "similarity_overview = linear_kernel(tfidf_matrix_overview,tfidf_matrix_overview)\n",
        "overview_based = overview_based.reset_index()\n",
        "index = pd.Series(overview_based.index, index=overview_based['title']).drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8LT8uE9NghzS"
      },
      "outputs": [],
      "source": [
        "# Girilen film ismine göre öneri yapacak olan fonksiyon :\n",
        "\n",
        "def recommend_by_overview(title, sim = similarity_overview) :\n",
        "  idx = index[title]\n",
        "  sim_score = list(enumerate(sim[idx]))\n",
        "  sim_score = sorted(sim_score, key=lambda x: x[1], reverse=True)\n",
        "  sim_score = sim_score[1:11]\n",
        "  movie_index = [i[0] for i in sim_score]\n",
        "  recommendation = overview_based['title'].iloc[movie_index].tolist()\n",
        "  recDict = {}\n",
        "  i = 0\n",
        "  while i < 10 :\n",
        "    recDict[recommendation[i]] = sim_score[i][1]\n",
        "    i += 1\n",
        "\n",
        "  return recDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDKc9wlgjD6z"
      },
      "source": [
        "### Cast, Crew, Keyword, Genre Bazlı Filtre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhQMiaPFiXVZ"
      },
      "outputs": [],
      "source": [
        "features = ['cast', 'crew', 'keywords', 'genres']\n",
        "feature_based = content_based[['title','cast', 'crew', 'keywords', 'genres']]\n",
        "\n",
        "for feature in features : \n",
        "  feature_based[feature] = feature_based[feature].apply(literal_eval)\n",
        "\n",
        "# Yönetmenleri crew sütunundan almak için gerekli fonksiyon  \n",
        "def add_director(j) :\n",
        "  for i in j :\n",
        "    if i['job'] == 'Director':\n",
        "      return i['name']\n",
        "  return np.nan\n",
        "\n",
        "# Diğer sütunlardaki bilgilerden ilk 5 tanesini almak için gerekli fonksiyon\n",
        "def add_list(j) :\n",
        "  if isinstance(j, list):\n",
        "        \n",
        "        names = [i['name'] for i in j]\n",
        "        \n",
        "        if len(names) > 5:\n",
        "            names = names[:5]\n",
        "        return names\n",
        "   \n",
        "  return []       \n",
        "\n",
        "# Veriyi kullanabilmek için uyumlu forma getirme işlemi\n",
        "feature_based['director'] = feature_based['crew'].apply(add_director)\n",
        "features = ['cast', 'keywords', 'genres']\n",
        "\n",
        "for feature in features:\n",
        "    feature_based[feature] = feature_based[feature].apply(add_list)\n",
        "\n",
        "feature_based = feature_based.drop(columns = ['crew'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z-G5nSKY_VXU"
      },
      "outputs": [],
      "source": [
        "# Bütun satırlardaki verileri küçük harfe dönüştürme ve boşlukları düzenleme işlemi \n",
        "def clean(j):\n",
        "    if isinstance(j, list):\n",
        "        return [str.lower(i.replace(\" \", \"\")) for i in j]\n",
        "    else:\n",
        "        if isinstance(j, str):\n",
        "            return str.lower(j.replace(\" \", \"\"))\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "features = ['cast', 'keywords', 'director', 'genres']\n",
        "\n",
        "for feature in features:\n",
        "    feature_based[feature] = feature_based[feature].apply(clean)\n",
        "\n",
        "# Vektörleştirme işlemini tek seferde yapabilmek için bütün verileri içeren tek bir sütun oluşturma işlemi\n",
        "def all_data(x):\n",
        "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
        "\n",
        "\n",
        "feature_based['all'] = feature_based.apply(all_data, axis=1)\n",
        "\n",
        "tf_idf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix_feature = tf_idf.fit_transform(feature_based['all'])\n",
        "\n",
        "# Filmler arasındaki benzerlikleri nümerik bir skorla görmek için 'cosine similarity score' hesabı yapma kararı aldım\n",
        "tfidf_matrix_feature.shape\n",
        "similarity_feature = linear_kernel(tfidf_matrix_feature,tfidf_matrix_feature)\n",
        "feature_based = feature_based.reset_index()\n",
        "index = pd.Series(feature_based.index, index=feature_based['title']).drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c-7VcMKRUpzK"
      },
      "outputs": [],
      "source": [
        "def recommend_by_feature(title, sim = similarity_feature) :\n",
        "  idx = index[title]\n",
        "  sim_score = list(enumerate(sim[idx]))\n",
        "  sim_score = sorted(sim_score, key=lambda x: x[1], reverse=True)\n",
        "  sim_score = sim_score[1:11]\n",
        "  movie_index = [i[0] for i in sim_score]\n",
        "  recommendation = feature_based['title'].iloc[movie_index].tolist()\n",
        "  recDict = {}\n",
        "  i = 0\n",
        "  while i < 10 :\n",
        "    recDict[recommendation[i]] = sim_score[i][1]\n",
        "    i += 1\n",
        "\n",
        "  return recDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eUPOCSLF2wD"
      },
      "outputs": [],
      "source": [
        "# İki filtreden de gelen veriler dictionary şeklinde olduğundan dolayı değerden anahtar kelimeyi bulan bir fonksiyona ihtiyacım oldu\n",
        "def get_key(d, val):\n",
        "    keys = [k for k, v in d.items() if v == val]\n",
        "    if keys:\n",
        "        return keys[0]\n",
        "    return None\n",
        "\n",
        "# Buradaki fonksiyonda iki filtreden gelen cosine similarity score değeri bir listeye atanıyor \n",
        "# Liste büyükten küçüğe sıralanıp değeri en büyük olan 10 film öneri olarak veriliyor\n",
        "def final_recommendation_content_based(title) :\n",
        "  list1 = recommend_by_overview(title)\n",
        "  list2 = recommend_by_feature(title)\n",
        "  value_list = list(list1.values()) + list(list2.values())\n",
        "  value_list.sort(reverse = True)\n",
        "  recommend_list = []\n",
        "  i = 0 \n",
        "  while i < 20 :\n",
        "    key = get_key(list1,value_list[i])\n",
        "    if key is None :\n",
        "      new_key = get_key(list2,value_list[i])\n",
        "      if new_key in recommend_list :\n",
        "        i += 1 \n",
        "        continue\n",
        "      else :\n",
        "        recommend_list.append(new_key)    \n",
        "    else :\n",
        "      if key in recommend_list :\n",
        "        i += 1 \n",
        "        continue\n",
        "      else :\n",
        "        recommend_list.append(key)  \n",
        "    i += 1  \n",
        "  recommend_list = recommend_list[0:10]\n",
        "  return recommend_list\n",
        "\n",
        "final_recommendation_content_based('The Godfather')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP1UCSdqVz8a"
      },
      "source": [
        "# Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User-Based Collaborative Filtering"
      ],
      "metadata": {
        "id": "3_YDk_3GynSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtre için veri hazırlığı\n",
        "movies = pd.read_csv('movies_metadata.csv')\n",
        "ratings = pd.read_csv('ratings.csv')\n",
        "movies = movies[['id','title']]\n",
        "movies['movieId'] = movies['id']\n",
        "movies = movies.drop('id', axis = 1)  "
      ],
      "metadata": {
        "id": "pTpXJ0wiDzHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVD ile kullanıcıya ve girdiği filme göre vereceği rating'i tahmin etme işlemi \n",
        "def collaborative_filter(movieID) : \n",
        "  reader = Reader()\n",
        "\n",
        "  data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "  svd = SVD()\n",
        "  cross_validate(svd, data, measures=['RMSE', 'MAE'])\n",
        "  trainset = data.build_full_trainset()\n",
        "  svd.fit(trainset)\n",
        "\n",
        "  score = str(svd.predict(2000, movieID, 3.5))\n",
        "  score = score.split()\n",
        "  return score[9]"
      ],
      "metadata": {
        "id": "-ByTEZlZMjCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demographic Filtering"
      ],
      "metadata": {
        "id": "9-4zTlt2Yzn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bu filtreleme çeşidi proje içerisinde pek önemli bir yer arz etmiyor. Tamamen popülerlik bazlı çalışmaktadır.\n",
        "movies_metadata = pd.read_csv('movies_metadata.csv')\n",
        "vote_average= movies_metadata['vote_average'].mean()\n",
        "vote_count= movies_metadata['vote_count'].quantile(0.9)\n",
        "\n",
        "demo_movies = movies_metadata.copy().loc[movies_metadata['vote_count'] >= vote_count]\n",
        "\n",
        "# IMDB'nin film değerlendirmesi için kullandığı formülü uygulayalım\n",
        "def weighted_rating(x, vote_count=vote_count, vote_average=vote_average):\n",
        "    vote_numbers = x['vote_count']\n",
        "    average = x['vote_average']\n",
        "    # Calculation based on the IMDB formula\n",
        "    return (vote_numbers/(vote_numbers+vote_count) * average) + (vote_count/(vote_count+vote_numbers) * vote_average)\n",
        "\n",
        "def demographic_recommender(demo_movies = demo_movies) : \n",
        "  demo_movies['score'] = demo_movies.apply(weighted_rating, axis=1)\n",
        "  demo_movies = demo_movies.sort_values('score', ascending=False)\n",
        "  return demo_movies['title'].head(10).tolist()    "
      ],
      "metadata": {
        "id": "K1D5R_UWY4mT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "HybridMovieRecommanderEngine.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIgCTzZTobTH9MJ++JTY9h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}